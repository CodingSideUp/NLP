{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqN0gZjqS8hc"
      },
      "source": [
        "\n",
        "# **Analytics 2 :** <font color=#DF4807>**Probabilisitc Models and Auto Complete**</font>\n",
        "\n",
        "**Objectives**:\n",
        "\n",
        "1. Pre-process the data\n",
        "2. Add Start and end Tokens\n",
        "3. Creating a vocabulary list of unique words\n",
        "4. Calculate ngram frequencies\n",
        "5. Calcualte Conditional Probabilities with k-smoothing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hgI4MESa9te",
        "outputId": "2dd3e950-9533-433f-ed94-559e84592101"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading twitter_samples|: <urlopen error [Errno\n",
            "[nltk_data]     11001] getaddrinfo failed>\n"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "import nltk\n",
        "from nltk.corpus import twitter_samples\n",
        "nltk.download('twitter_samples|')\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxLrxQc38GaB"
      },
      "source": [
        "## **Loading the Data:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeT3pI_1S8hk",
        "outputId": "ea5e3b0f-f2c7-4f6b-8a8c-88b558a2d0bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
              " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
              " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
              " '@97sides CONGRATS :)',\n",
              " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets = twitter_samples.strings('positive_tweets.json')\n",
        "tweets[:5] #let's look at a sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU6oj0tT8LZN"
      },
      "source": [
        "## **Pre-processing text data:**\n",
        "\n",
        "1. split data into sentences\n",
        "2. split each sentence into tokens\n",
        "3. additional pre-processing that you think would be benefitial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HkdTdB-iS8hq"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_sentences  = []\n",
        "for each_sentence in tweets:\n",
        "    sentence = []\n",
        "    for each_word in each_sentence.split():\n",
        "        # Converting to lower case if it's not starting with # or @\n",
        "        if not each_word.startswith('#') or each_word.startswith('@'):\n",
        "            sentence.append(each_word.lower())\n",
        "        else:\n",
        "            sentence.append(each_word)\n",
        "        # sentence.append(each_word.text)\n",
        "    # Inserting <start> and <end> in the beginning and the ending of the sentence.\n",
        "    sentence.insert(0,'<start>')\n",
        "    sentence.insert(len(sentence)+1,'<end>')\n",
        "    # Adding all the sentences after tokenization \n",
        "    all_sentences.append(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvvgYzrlnCi6"
      },
      "source": [
        "## **Create Vocabulary list:**\n",
        "We won't be using all the vocabulary in our dataset. Instead we will set a threshold and only use the vocabulary that appear more than that given threshold. This is to remove words which aren't important.\n",
        "\n",
        "**Task 1:** First we need to calcualte word frequencies. Let's create a dictionary with all the unique words in the data and the frequency in which they appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5lNkC0Y5OYns"
      },
      "outputs": [],
      "source": [
        "word_freqs = {} #getting the frequency of all the words that occur in our data\n",
        "#your code here:\n",
        "\n",
        "#calculating the word frequency\n",
        "for sentence in all_sentences:\n",
        "    for each_word in sentence:\n",
        "        # Checking if the words are already created.\n",
        "        if each_word in  word_freqs.keys():\n",
        "            word_freqs[each_word] += 1\n",
        "        else:\n",
        "            word_freqs[each_word] = 1\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozk7FUmPV8-J"
      },
      "source": [
        "**Task 2:**  Now, we create our vocabulary using words above a certain frequency threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "c0z1UkkisgEh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['#FollowFriday', 'for', 'being', 'top', 'engaged', 'members', 'in', 'my', 'community', 'this', 'week', ':)', 'hey', 'james!', 'how', ':/', 'please', 'call', 'our', 'contact', 'on', 'and', 'we', 'will', 'be', 'able', 'to', 'you', 'many', 'thanks!', 'had', 'a', 'listen', 'last', 'night', 'as', 'is', 'an', 'amazing', 'when', 'are', 'congrats', 'has', 'got', 'blue', 'fb', '15', 'days', '@bhaktisbanter', '@pallaviruhail', 'one', '#FlipkartFashionFriday', \"don't\", 'like', 'keep', 'lovely', 'waiting', 'hope', 'enjoy!', 'happy', 'friday!', '-', 'second', 'just', 'not', 'enough', 'time', 'but', 'new', 'must', 'jgh', ',', 'have', 'go', ':d', 'bye', 'act', 'of', 'am', 'calling', 'the', 'app', 'name', 'influencers', 'who', \"wouldn't\", 'love', 'these', 'big....juicy....selfies', 'follow', '@jnlazts', '&amp;', 'http://t.co/rcvcyyo0iq', 'u', 'back', 'so', 'already', 'know', \"what's\", 'great', 'opportunity', '12', '13', 'at', 'get', 'your', 'out', 'greetings', 'card', 'today', 'job', ':-)', \"friend's\", 'it', 'id', 'thanks', 'help', \"here's\", 'working', 'hi', ':))', 'hello', 'i', 'need', 'something', 'can', 'me', '—', 'sure', 'thing', 'dm', 'x', 'followers', \"i've\", 'heard', 'four', 'pretty', 'fun', \"y'all\", '@gculloty87', 'yeah', 'suppose', 'she', 'was', 'lol!', 'chat', 'bit', 'off', 'youth', 'opportunities', '&gt;&gt;', '@tolajobjobs', ':))))', \"haven't\", 'seen', 'years', 'thank', 'you!', 'rest', 'goes', 'by', 'music', 'fix', 'now', 'dream', 'festival', 'beginning', 'line-up', 'left', '(y)', 'see', 'more', 'send', 'us', 'email', \"we'll\", 'asap', 'kik', '#kik', '@kalinwhite', 'come', 'house', ':)))))', 'release', 'with', 'bam', '!', '@barsandmelody', 'bestfriend', '@969horan696', '?', 'loves', 'lot', 'warsaw', '&lt;3', 'everyone', 'watch', 'youtube', 'supports', 'oh', 'well', 'looking', 'forward', 'visiting', 'next', 'if', 'makes', 'feel', 'better', 'never', 'anyone', 'good', 'you,', 'best', 'wishes', 'reason', 'shout', 'out.', 'friday', 'added', 'video', '@youtube', 'playlist', 'im', 'twitch', 'going', 'league', '1', '/', '4', 'would', 'dear', 'oh,', 'okay', ';)', 'haha', 'do', 'stuff', ':).', 'exactly', 'product', 'line', 'shop', 'now!', 'check', 'vacation', 'great!', 'they', 'comes', 'buy', \"she's\", 'asleep', 'no', 'talk', 'sooo', 'someone', 'text', 'yes,', 'bet', \"he'll\", 'after', 'her', 'today.', 'pity', 'beautiful', 'till', 'future', 'here', 'u,', 'change', 'big', 'only', 'why', 'stand', 'up', ':)\"', 'god', 'baby', \"can't\", 'wait', 'signed', 'yet,', 'or', 'still', 'thinking', 'about', 'it?', 'mka', 'liam', 'most', 'welcome', 'stats', 'day', 'arrived.', 'follower', 'unfollowers', 'via', \"shouldn't\", 'figure', '@emilybett', 'wishing', 'all', '2', 'plans', 'down', ':):', '@5sos_fahupdates', 'gotta', ':p', 'parents', 'proud', 'least', 'maybe', 'sometimes', 'because', 'let', \"you're\", 'side', 'world', 'too', 'take', 'care', 'finally', 'fucking', 'weekend', 'real', 'yes!', 'joined', 'gift', 'from', '@hushedapp', 'make', ':)))', 'event', 'might', 'day!', 'luv', 'really', 'appreciate', 'share', 'around', '@tomparker', 'that', 'tom', '3', 'gym', 'monday', 'likes', 'hey,', 'invite', 'join', 'scope', 'influencer', 'http://t.co/rzgztq2fjt', 'those', 'friends', 'sleep', 'birthday', 'today!', 'want', 'cool', 'mom', 'him', '@zaynmalik', 'luck', '!!', 'glad', 'twitter.', 'joining', 'again', 'done', 'its', 'lets', 'read', 'before', 'doing', 'become', 'details', 'here:', 'http://t.co/ipj2yoiget', 'xx', 'hashtag', 'miss', 'sounds', \"that's\", 'definitely', 'try', 'tonight', 'then!', 'took', 'advice', 'too!', 'hi!', '@impastel', 'concert?', 'city', 'country', \"i'll\", 'start', 'it!', 'gorgeous', 'sun', 'some', 'right', \"doesn't\", 'even', 'almost', 'then', 'chance', 'cheers', 'ice', 'cream', 'agree', '100%', '@spazzytsukihara', 'thats', 'point', 'stay', 'home', 'soon,', 'promise', 'web', 'whatsapp', 'iphone', 'plan', 'watching', '34', 'mins', 'w', 'message', 'wan', 'he', 'sits', 'luke', 'small', 'team,', '(@', 'station', 'west', \"it's\", 'live', 'strange', 'imagine', '@bookmyshow', '#MasaanToday', '@wforwoman', 'over', '20', 'half', 'number', '#WSaleLove', 'anyway', 'kinda', 'lol.', 'well.', 'life', 'surely', 'could', 'morning', '???', 'coming', 'bath', '@justinbieber', 'always', 'smile', '@arsenalnewsasit', 'again,', 'right?', 'perfect', 'timing', 'given', 'long', 'feeling', 'delighted', 'having', 'missed', 'songs', 'ever', 'shall', 'own', 'little', 'throwback', 'such', 'different', \"i'm\", 'totally', 'yours', \"let's\", 'go...', 'drive', '#traveling', '#traveler', '#yogyakarta', '#jeep', '#Indonesia', '#instamood…', 'wanna', 'me?', 'may', 'look', 'so,', 'nice', 'girl', 'them.', 'where', 'film', 'congratulations', 'winner', 'contest', 'address', 'guys!', 'seeing', \"won't\", 'regret', '...', 'hours', 'leave', 'now,', 'without', 'actually', 'very', 'easy', 'this,', 'guess', 'train', 'hour', 'visit', 'blog', 'http://t.co/uzoaqrowkx', 'me.', 'huge', 'warm', 'complete', 'what', 'hug', ':*', 'connect', '@meatbingo', 'wonderful', 'made', 'trip', \"i'd\", 'there', 'question', 'pain', 'went', 'solo', \"weren't\", 'fav', 'song', 'spirit', 'rip', ':-)))))', 'did', 'couple', '??', 'vid', 'wake', 'gonna', 'shoot', 'picture', 'much', '4th', 'gets', 'rain', 'fabulous', 'fantastic', 'all!', 'hear', 'night!', 'bed', 'idea', 'game', \"didn't\", 'pic', 'phone', 'night.', 'using', 'track', 'stress', 'guys', 'turning', '17', 'well,', 'say', 'find', 'hard', 'believe', 'course', 'yes', 'there,', 'info', \"we'd\", 'help!', 'way', 'high', 'people', 'smile.', 'does', 'trust', 'k', 'sorted', 'smart', 'hair', 'tbh', '5', 'tee', 'man', 'family', '..', '[pic]', 'reading', 'beautiful.', 'talking', 'person', '....', 'two', ':))))))))', 'should', 'online', '#Friday', '#FridayFeeling', '#TGIF', 'ya', 'allah', \"we're\", 'training', 'w/', 'drop', 'town', 'basically', 'cup', 'test', 'also,', 'twitter', 'snapchat', ':', '#snapchat', '#kikmenow', '#hot', '#kikmeguys', 'shift', ':))))))', 'growing', 'rt', '...and', 'writing', 'since', 'mentioned', 'fly', 'other', 'getting', 'follows', 'lol', '@gurmeetramrahim', '#OurDaughtersOurPride', 'positive', 'also', 'mention', ':d.', 'though', 'haha.', 'yes.', 'touch', 'kepler', 'hai', 'thankyou', 'food', 'awake', 'awww', 'ha!', 'surprise', 'wow!', 'won', 'travel', 'hurt', 'bad', 'mine', 'saturday', ':-))))', 'true', 'that.', 'used', 'them', 'probably', 'funny', 'ate', 'mate', 'literally', \"they're\", 'updating', 'log', '@vikkfollows', 'bring', 'same', 'meet', '#quacketyquack', 'happened', ')', 'hi,', 'play', 'yeah!', 'out!', 'fans', 'knowing', 'there.', 'playing', 'brain', 'dots', '#BrainDots', 'fair', 'selfie', 'during', 'men', 'put', 'their', 'site', 'free', '50.000', '8', 'ball', 'pool', 'coins.', 'loved', '♥', '=', 'happiness', 'post', 'three', 'things', 'grateful', 'comments', 'hot', 'louis', \"he's\", 'throw', 'cause', 'inspire', 'think', 'better.', '#FF', 'twoofs', 'http://t.co/fiypr3t2ai', 'wish', 'year', 'kind', 'liked', 'it..', 'time.', 'words', 'much!', 'please?', 'ruin', 'open', 'fuck', 'guys.', 'work', 'it.', 'looks', 'you.', 'than', 'which', 'use', 'recent', 'into', '#TeenChoice', '#ChoiceInternationalArtist', '#SuperJunior!', 'first', 'salmon', 'enjoyed', 'following!', \"you'd\", 'any', 'awesome', 'stream', '@', 'school', 'uk', 'single', 'listening', 'hills', 'every', 'wrong', 'everything', 'ready', 'garden', 'tomorrow', ':-))', 'remember', 'heads', 'saw', 'thought', '\"dark\"', '.plz', 'cute', 'meeting', 'hate', 'cant', 'decide', 'save', 'list', 'show', 'awesome,', 'perfect.', 'enjoy', 'photos', 'thx', 'support', 'girl.', 'either', 'give', 'mind', 'lovely!', 'quite', 'radio', 'set', 'heart', 'ily', 'sorry', 'typed', 'came', 'old', 'bro', 'sweet', 'michael', 'cheers,', 'usually', 'front', 'soon', 'dan', 'brand', 'head', 'up.', 'officially', 'thanks.', 'expert', 'yo', 'book', 'dinner', 'tonight!', 'choice', 'others', 'chill', 'now.', 'moment', 'onto', 'account', 'been', 'girl,', 'apparently', 'member', 'hopefully', 'changes', 'design,', 'https://t.co/ext098yq1b', 'that!', 'official', 'form', 'ur', 'surreal', 'going?', 'mental', 'latest', 'c', '\\\\o/', 'funny,', 'it,', 'singer', 'again!', 'order', 'takes', 'room', 'car', 'once', 'gone', 'streaming', 'hahaha', 'story', 'related', 'due', 'starting', 'received', 'rn', 'whatever', 'success', '@mikeyygee_562', '@thatdudegalvan_', 'few', 'moments', \"there's\", 'finished', 'happy.', 'needs', 'years.', 'blessed', 'sense', 'main', '|', 'months', 'yay!', 'babe', 'lovely,', 'peaceful', 'nights', 'up,', 'dreams', 'that,', 'much.', 'tuned', 'mother', 'james', 'girls', 'changed', 'time,', '#HappyFriday', 'nearly', 'retweeted', 'updated', 'sure.', 'sign', 'tweets', 'fine', 'nope', 'apply', 'ah,', 'found', 'i’m', 'leg', 'perhaps', 'bb', 'full', 'album', 'september', 'write', 'possible', 'while', '6', '&gt;:d', '#OTWOLGrandTrailer', 'fact', 'beat', 'ni', 'day,', 'lots', 'interview', 'august', 'fulfil', 'fantasies', '👉', 'against', '#ff', 'ideas', 'living', 'welcome,', 'interested', 'sad', 'work.', 'win', '#FreebieFriday', 'john', 'do!', 'until', 'quit', 'work!', 'followed', 'end', 'breaking', 'to.', 'welcome.', '@astonmerrygold', 'excited', '@kageyashsa', 'shopping', 'needed', 'summer', 'younger', 'woman', \"aren't\", 'expect', 'anything', 'night,', 'dont', '10', 'loners', 'word', 'spreading', 'near', 'gold', 'soon.', 'yay', 'someday', 'r', 'n', 'forget', 'sis', 'drawing', 'connecting.', 'specialise', 'thermal', 'imaging', 'surveys', '–', 'planning', 'korea', 'facts', 'slept', 'through', \"ain't\", 'xd', 'yep', 'place', 'completely', 'under', 'worth', 'bringing', 'tho', 'outside', ':)))))))', 'both', 'weekend!', '❤️', 'atm', 'retweets', '\"i', 'bra', 'knows', 'season', 'speak', 'add', 'collection', '#follow', 'report', 'stories', 'were', 'close', 'followback', ':-d', 'dead', 'aww', '#StarSquad', '⭐', 'follow?', 'awesome!', 'awwww', 'news', '@bravefrontiergl', 'd', 'problem', 'hurry', 'somewhere', 'later', 'click', 'link', 'following', 'available', '#JabongatPumaUrbanStampede', '@jabongindia', 'bill', 'ok,', 'says', 'inside', 'ship', 'ask', 'too.', '@vivienneclore', 'fun.', '@ollyofficial', 'talented', '_', 'tired', 'tell', ':):):)', 'pls', 'past', 'interesting', ':3', '2nd', 'reviews', 'cutie', 'v', 'far', 'things,', 'favorite', 'subject', 'stopped', 'best,', 'secret', 'behind', '#CEO1Month', 'turn', 'seems', 'young', 'understand', 'another', 'beach', '@jonscrazytweets', 'welcome!', 'movie', 'back!', 'else', 'pics', 'chocolate', 'tea', 'episode', '.', 'camera', 'drink', 'dj', 'again.', 'di', 'ko', 'ugly', 'la', 'board', 'stuck', 'sponsor', '@real_liam_payne', 'goodnight', 'yeah,', 'arrived', 'morning!', 'ill', 'sick', 'science', 'helping', 'move', 'nothing', 'sharing', 'products', 'especially', 'bout', 'making', 'follback', 'pro', 'store', ':-)...', 'pack', 'tweet', 'hit', 'snap', 'bought', 'bday', 'fan', 'you!!', 'whenever', 'g', 'hugs', 'package', 'enter', 'works', 'worry', 'low', 'match', 'fback?', 'harry', 'bc', 'friend', \"how's\", 'body', '7', 'woke', \"people's\", 'kid', 'sunshine', 'weeks', 'die', 'laugh', '#summer', 'ride', 'anytime', 'taste', 'team', 'short', 'among', 'australia', ':),', 'chelsea', 'hang', 'hehe', 'said', 'facebook', '#kikmeboys', '#photooftheday', 'his', 'office', 'weather', 'wedding', 'incredible', 'pictures', 'weekend.', '#friday', 'vote', 'done!', 'peace', '@5sos', 'late', 'though.', 'exciting', 'swear', 'met', 'smiling', 'french', 'france', 'videos', 'feedback', 'ours', 'page', 'coffee', 'panda', 'favourite', 'rettweet', 'madrid', 'starts', 'sore', 'excellent', 'movies', 'good!', 'dates', 'indeed', 'strong', 'no,', ':-)))', 'ok', 'busy', 'forgot', 'dress', 'oil', 'cannot', 'buyers', 'true,', 'paper', 'know,', 'less', 'record', 'art', 'super', 'ka', 'quick', 'layout', 'feed', 'beauty', 'mail', 'wants', 'me!!', 'watched', 'yesterday', '@outboundapp', 'sharing!', 'wicked', 'sending', 'btw', 'photoset:', 'ty', 'shit', '@adeccowaytowork', '@adeccojapan', 'suck', 'turns', 'special', 'part', 'morning.', 'filled', 'day.', '5sos', 'unless', 'wonder', 'boy', 'buddy!', 'questions', 'amazing!', 'absolutely', 'classic', 'truth.', ';-)', '#PSYGustoKita', 'afternoon', 'break', 'run', '^mm', 'brilliant', 'finding', 'us!', 'started', 'waking', \"'s\", 'unexpected', 'create', 'students', 'catch', 'this!', 'quote', 'weird', 'poor', 'zonzofox', 'brother', 'lucky', 'dog', 'blog!', 'project', 'service', 'mean', 'safe', 'pass', 'xxx', 'ago', 'trying', \"who's\", 'shot', 'wow', 'tv', 'outfit', 'wanted', 'go!', 'skin', 'important', '@chelsea_acker', 'whoop', 'whoop!', 'it!!', 'party', 'means', 'ha', 'mi', 'guys,', 'them,', 'talks', 'issue', 'light', 'social', 'design', 'alright', 'windows', 'asking', 'stupid', 'question.', 'loving', 'tickets', 'early', 'london', 'provide', 'fresh', 'water', '…', '+', 'business', 'tuesday', 'keeps', 'putting', '@otraclace', 'sa', 'appreciated', ':-*', 'deserve', 'fab', ':d\"', 'doesnt', 'here,', '@babypuffinator', '@carlhamlet', 'suggestion', 'filming', 'back.', 'retweet', 'tried', 'everyone,', 'tomorrow.', 'everyone!', 'here.', '#BajrangiBhaijaanHighestWeek1', 'me,', 'learn', 'fun!', 'instead', 'plus', 'sent', 'gamer', 'train!', 'gain', 'active', 'comment', 'final', 'cat', 'box', 'problems', 'spotify', \"we've\", 'mega', 'launch', 'keeping', '💜', 'na', 'ellie', 'pleasure', 'death', 'fell', 'earlier', 'dude', \"you'll\", 'fall', 'wait!', 'bus', 'everytime', 'way,', 'hold', 'photo', 'tomorrow?', 'omg', 'class', '@womadcharltonpk', \"today's\", 'normal', 'married', 'whats', 'job!', '2015', 'released', 'england', 'giving', 'certainly', 'kindly', 'jealous', 'sound', 'gave', '😂', 'hun', 'doubt', '200', 'we?', 'mood', 'stop', 'good.', 'whole', '@ileana_official', 'bless', 'loose', 'pay', 'article', '@thebetterindia', '#BellyButton', '#Innie', '#Outie?', 'havent', \"they'll\", 'anymore', 'matt', 'probs', 'honestly', 'is,', 'pick', 'employers!', 'today?', 'honest', 'happen', 'friday.', 'tgif!', 'cry', 'sunday', 'imran', 'khan', 'sir', '&gt;', 'size', 'request', 'media', 'sucks', 'driving', 'red', 'matter', '#happy', 'wear', 'realized', '#kiksexting', 'plz', '11', 'money', 'india', 'talked', 'drama', 'fun?', '#l4l', 'experience', 'ad', 'extra', 'points', 'ji', 'knew', 'burn', '@stefaniescott', 'sexy', '@eonnicchi', 'ah', 'you?', 'lesson', 'hands', 'rose,', 'type', 'offer', 'af', 'company', 'peeps', 'rough', 'changing', 'ladies!', 'library', 'jumma', 'earth', 'thanks,', 'pleased', 'retweet!', 'ohhh', 'wondering', 'grow', 'bag', ':-).', 'yaa', 'view', 'books', 'photo:', 'website', 'myself', 'times', 'black', '9', 'bored', 'tour', 'holidays', 'count', 'alice', 'goodbye', 'ye', 'se', 'date', 'guy', 'cheese', 'fudge', 'lil', 'yet', 'breakfast', 'saying', 'good,', 'calm', 'haha!', 'tweet,', 'grab', 'gd', 'roll', 'vids', '-mary', 'yourself', 'cover', 'wine', '@jazminbonilla77', 'jazmin', 'bonilla', 'stars', 'kim', 'bio', 'sisters', 'told', 'race', 'human', \"isn't\", 'tweeting', 'hilarious', 'kath', 'model', 'us.', 'ticket', 'views', 'asked', 'back?', 'notice', 'taking', 'fast', 'hell', 'park', 'hoping', 'fri', 'oppa', '^_^', 'current', 'hear!', 'please!', 'road', '^^', 'boring', 'chicken', 'chips', 'latin', 'queen', 'asian', 'version', '#kikgirl', 'awesome.', 'children', 'route', 'donna!', 'dad', 'grandpa', 'iph0ne', 'free?', 'simply', 'bi0.', 'afraid', 'minecraft', 'drew', 'group', 'huhu', 'tweet.', '!!!', 'english', 'hey!', '😊', 'walk', 'emails', 'flowers', 'wont', 'fruit', 'lot.', 'ma', 'rock', '@cg_rated', 'labour', 'leader', '@joohyunvrl', 'don’t', 'instagram?', 'away', 'h', '@avonfvcks', '#NotAnApology', 'month', '@sculptorfred', 'virgin', 'speaking', 'this.', 'b', 'urgently', 'within!', 'place!', 'sister', 'copy', 'anniversary', 'folks', 'case', 'bae', 'bonding', '@whittakerdesig1', '@sweettoothmarti', 'each', \"you've\", 'away.', 'session', 'pre', 'star', '#art', 'one.', 'follow!', 'million', 'too!!', 'crazy', 'soon!', 'treat', '@grahamtownsend', 'rather', 'nite', 'mature', 'lack', 'weekend?', '40', 'download', 'apple', 'style', '@natsu1725', '#KunoriforCEO', 'me!', '~', 'beyond', 'running', 'video)', 'brings', 'all.', 'sitting', 'tag', 'section', 'law', 'hearts', 'days,', 'along', 'process', '70', \"wasn't\", 'felt', 'support!', '#smile', 'enough?', 'yah', 'shoulda', 'ones', 'giveaway', 'king', '@humna__khan', 'lunch', 'worked', 'lines', 'pop', 'vs', 'fellow', 'fourfiveseconds', '\"deaf', 'ears\"', 'apexis', 'crystal', 'refreshing', 'nap', 'original', 'kids', 'google', 'present', 'word,', 'shining', 'sunny', '#cute', 'eat', 'fingers', 'crossed', 'indeed.', 'mubarak', \"couldn't\", 'jesus', '3rd', 'smiles', 'gives', 'enjoying', 'archdbanterbury', 'face', 'plays', 'july', '@magicbricks', '#GOHF', 'gooday!', 'answer', 'tells', 'code', 'kidding', '#holiday', '@mariasharapova', 'sweetie', 'belated', 'spread', '#xxx', '#tagsforlikes', 'likewise', 'riding', 'power', 'actually,', 'hero', 'course,', 'club', 'haha,', 'eyes', 'crying', 'happy,', '#food', 'fighting', 'walking', '@lovingjeonboram', 'eye', 'right.', '@pb_furniture', 'otherwise', '🍰', 'idea,', 'me:', 'yup,', 'aw', 'color', 'pleasse', 'true.', 'haters', 'cuz', 'sleeping', 'edit', 'called', '@miabellasesso', 'air', 'mobile', 'application', 'cycling', 'quality', 'beth', 'remix', 'rubber', 'ducks', 'wolf', '*', '\"the', ':)\"@kreizi_:', '#retweet', 'minutes', 'series', 'skills', \"it'll\", 'great,', 'responses', '#sex', 'interested,', 'following!!', 'tweets!', 'friends!', 'routine', 'favor', 'sneak', 'orders', '@klick_business', '6?', 'gud', 'weight', 'clap', '#indiemusic', 'sexyjudy19', '#pussy', '#gay', '#sexo', '❤💙💚💕❤💙💚💕', 'texting', '#AutoFollow', '#TeamFollowback', 'http://t.co/chhwq9dhgo', 'http://t.co/xmohgowivj', 'sleep,', 'dat', 'mr', '#غردلي', '@carterreynolds', 'lose', '#goodmorning', 'study', 'indeed!', 'cousins', '#music', 'goodness', 'angry', '(animation)', '#Minecraft', '←', 'aqui', 'w.o.t.!!!', '(no', 'download)', 'tanks', '\"@yettygeers:', 'nba', '2k15', 'mypark', 'chronicles', 'gryph:', 'volume', 'decision', 'man.', 'regular', 'countries', 'large', 'update', 'stunning', 'biggest', 'loser', 'unfollow', 'hurts', 'workout', '👏', 'babe!', 'on,', 'boys', 'ghost', 'worse', 'birthday!!', '💕', 'sabah', 'jummah', '♡', 'booked', 'consistency', 'sing', '@sasarichardson', '@stefbystef_', '@frgt10_anthem', 'white', 'celebrating', 'truly', 'well!', 'kfcroleplayers', 'friend!', 'idk', 'lfc', 'spotting', 'weakness', '@louis_tomlinson', 'speaker', 'bulbs', 'corn', 'waste.', 'imma', 'https://t.co/sc9kdhavix', 'http://t.co/j3sxzzg7cu', 'tha', 'approve', 'fanbase', 'bailona', '✫', '✧', '˚', '·', '✵', '⊹']\n"
          ]
        }
      ],
      "source": [
        "# Empty list for closed vocabulary\n",
        "\n",
        "#your code here\n",
        "vocabulary = []\n",
        "# Setting the upper Threshold and lower threshold\n",
        "upper_threshold = 3500 #You might need to do some testing on this first to get an idea of how your data is distributed.\n",
        "\n",
        "\n",
        "lower_threshold = 2\n",
        "\n",
        "# Fetching all the vocab after \n",
        "vocabulary = [ key for key,value in word_freqs.items() if value < upper_threshold and value > lower_threshold]\n",
        "print(vocabulary)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t93qGUEyksRn"
      },
      "source": [
        "## **Dealing with Unknown Words:**\n",
        "\n",
        "What happens when your model encounters a word which it has never seen before? In such a case, your model won't be able to make a prediction because there are no counts of that word. So, to be able to make predictions, we are going to include an \"unknown\" token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tywR93NrlSh8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', '<unk>', '<unk>', 'Curious.']\n"
          ]
        }
      ],
      "source": [
        "#go through your sentences again and replace words with (\"<unk>\") if they  are not in our vocabulary list.\n",
        "new_sentence = 'I love being Curious.'\n",
        "print([each if each not in vocabulary else '<unk>' for each in new_sentence.split() ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmUmR_DVS8hx"
      },
      "source": [
        "## **Add Start and End Tokens:**\n",
        "\n",
        "To be albe to calculate conditional probabilites for the first and last words in our sentences, we will inlclude 2 new tokens into our data. These are:\n",
        "\n",
        "<'start'> and <'end'>.\n",
        "\n",
        "For example:\n",
        "\n",
        "I went to the store. --> [<'start'>, i , went, to, the, store, <'end'>]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMzN9M80J4bV"
      },
      "source": [
        "## **bigram Frequencies:**\n",
        "\n",
        "Create a dictionary for bigrams with a key (bigram) value (count) pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OKSLmdNIv0PY"
      },
      "outputs": [],
      "source": [
        "#task 1: add start and end tokens to the sentences\n",
        "# all_sentences[0]\n",
        "#task 2: Create a dictionary for with the bigrams frequencies i.e. a key (bigram) value (count) pair.\n",
        "\n",
        "def create_n_gram(n):\n",
        "    \n",
        "    global all_sentences\n",
        "    word_freqs = {}\n",
        "    for sentence in all_sentences:\n",
        "        for index,each_word in enumerate(sentence):\n",
        "            ngram_words = \" \".join(sentence[index:index+n])\n",
        "            if ngram_words in  word_freqs.keys():\n",
        "                \n",
        "                word_freqs[ngram_words] += 1\n",
        "            else:\n",
        "                word_freqs[ngram_words] = 1\n",
        "                \n",
        "    return word_freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_vocab = create_n_gram(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzhFB-mIREyC"
      },
      "source": [
        "## **Ngram Probabilities with K-smoothing:**\n",
        "\n",
        "The next step involves us converting the frequencies to probabilities. For this purpose we will use Function 1:\n",
        "\\\n",
        "\\\n",
        "$$ \\hat{P}(w_t | w_{t-n} \\dots w_{t-1}) = \\frac{Count(w_{t-n}\\dots w_{t-1}, w_t)}{Count(w_{t-n}\\dots w_{t-1})} \\tag{1} $$\n",
        "\\\n",
        "\\\n",
        "In other words, the probability of current word following the previous word(s) = count(prev word(s), current word)/ count(previous word(s). However, this can be probalematic when probabilites are zero. To avoid this, we use smooothing techniques, one of which is k-smoothing.\n",
        "\\\n",
        "\\\n",
        "$$ \\hat{P}(w_t | w_{t-n} \\dots w_{t-1}) = \\frac{Count(w_{t-n}\\dots w_{t-1}, w_t) + k}{Count(w_{t-n}\\dots w_{t-1}) + k|V|} \\tag{2} $$\n",
        "\\\n",
        "\\\n",
        "In this approach, we add a constant to the numerator and we add the same constant* length of vocabualry to the denominator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "p-Pv3Uxr-BbP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number times thanks occurs is: 55\n",
            "Without K-smoothing 0.41353383458646614\n",
            "With K-smoothing 55.0000339673913\n"
          ]
        }
      ],
      "source": [
        "#count of the times \":)\" followed \"thanks\"\n",
        "all_vocab['thanks :)']\n",
        "\n",
        "all_thanks = [key for key in all_vocab.keys() if 'thanks' in key.split()[0]]\n",
        "all_smile = [key for key in all_vocab.keys() if ':)' in key]\n",
        "\n",
        "uni_gram_length = len(create_n_gram(1).keys())\n",
        "bi_gram_length = len(all_vocab.keys())\n",
        "\n",
        "print(f\"The number times thanks occurs is: {all_vocab['thanks :)'] }\")\n",
        "\n",
        "#let's calculate the probability of getting a happy face \":)\" after \"thanks\" with k smoothing\n",
        "k = 0.01\n",
        "prob_thanks_given_happy_face = all_vocab['thanks :)'] / len(all_thanks)\n",
        "prob_thanks_given_happy_face\n",
        "print(f\"Without K-smoothing {prob_thanks_given_happy_face}\")\n",
        "\n",
        "prob_thanks_given_happy_face = all_vocab['thanks :)'] + k / (len(all_thanks) + (k*uni_gram_length))\n",
        "prob_thanks_given_happy_face\n",
        "\n",
        "print(f\"With K-smoothing {prob_thanks_given_happy_face}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<start> #FollowFriday @france_inte': 1,\n",
              " '#FollowFriday @france_inte @pkuchly57': 1,\n",
              " '@france_inte @pkuchly57 @milipol_paris': 1,\n",
              " '@pkuchly57 @milipol_paris for': 1,\n",
              " '@milipol_paris for being': 1,\n",
              " 'for being top': 26,\n",
              " 'being top engaged': 6,\n",
              " 'top engaged members': 6,\n",
              " 'engaged members in': 6,\n",
              " 'members in my': 6,\n",
              " 'in my community': 24,\n",
              " 'my community this': 24,\n",
              " 'community this week': 24,\n",
              " 'this week :)': 25,\n",
              " 'week :) <end>': 23,\n",
              " ':) <end>': 1843,\n",
              " '<end>': 5000,\n",
              " '<start> @lamb2ja hey': 1,\n",
              " '@lamb2ja hey james!': 1,\n",
              " 'hey james! how': 1,\n",
              " 'james! how odd': 1,\n",
              " 'how odd :/': 1,\n",
              " 'odd :/ please': 1,\n",
              " ':/ please call': 1,\n",
              " 'please call our': 1,\n",
              " 'call our contact': 1,\n",
              " 'our contact centre': 1,\n",
              " 'contact centre on': 1,\n",
              " 'centre on 02392441234': 1,\n",
              " 'on 02392441234 and': 1,\n",
              " '02392441234 and we': 1,\n",
              " 'and we will': 3,\n",
              " 'we will be': 5,\n",
              " 'will be able': 3,\n",
              " 'be able to': 6,\n",
              " 'able to assist': 1,\n",
              " 'to assist you': 1,\n",
              " 'assist you :)': 1,\n",
              " 'you :) many': 1,\n",
              " ':) many thanks!': 1,\n",
              " 'many thanks! <end>': 1,\n",
              " 'thanks! <end>': 3,\n",
              " '<start> @despiteofficial we': 1,\n",
              " '@despiteofficial we had': 1,\n",
              " 'we had a': 2,\n",
              " 'had a listen': 1,\n",
              " 'a listen last': 1,\n",
              " 'listen last night': 1,\n",
              " 'last night :)': 2,\n",
              " 'night :) as': 1,\n",
              " ':) as you': 1,\n",
              " 'as you bleed': 1,\n",
              " 'you bleed is': 1,\n",
              " 'bleed is an': 1,\n",
              " 'is an amazing': 1,\n",
              " 'an amazing track.': 1,\n",
              " 'amazing track. when': 1,\n",
              " 'track. when are': 1,\n",
              " 'when are you': 1,\n",
              " 'are you in': 2,\n",
              " 'you in scotland?!': 1,\n",
              " 'in scotland?! <end>': 1,\n",
              " 'scotland?! <end>': 1,\n",
              " '<start> @97sides congrats': 1,\n",
              " '@97sides congrats :)': 1,\n",
              " 'congrats :) <end>': 3,\n",
              " '<start> yeaaaah yippppy!!!': 1,\n",
              " 'yeaaaah yippppy!!! my': 1,\n",
              " 'yippppy!!! my accnt': 1,\n",
              " 'my accnt verified': 1,\n",
              " 'accnt verified rqst': 1,\n",
              " 'verified rqst has': 1,\n",
              " 'rqst has succeed': 1,\n",
              " 'has succeed got': 1,\n",
              " 'succeed got a': 1,\n",
              " 'got a blue': 1,\n",
              " 'a blue tick': 1,\n",
              " 'blue tick mark': 1,\n",
              " 'tick mark on': 1,\n",
              " 'mark on my': 1,\n",
              " 'on my fb': 2,\n",
              " 'my fb profile': 1,\n",
              " 'fb profile :)': 1,\n",
              " 'profile :) in': 1,\n",
              " ':) in 15': 1,\n",
              " 'in 15 days': 1,\n",
              " '15 days <end>': 1,\n",
              " 'days <end>': 1,\n",
              " '<start> @bhaktisbanter @pallaviruhail': 5,\n",
              " '@bhaktisbanter @pallaviruhail this': 2,\n",
              " '@pallaviruhail this one': 2,\n",
              " 'this one is': 2,\n",
              " 'one is irresistible': 2,\n",
              " 'is irresistible :)': 2,\n",
              " 'irresistible :) #FlipkartFashionFriday': 2,\n",
              " ':) #FlipkartFashionFriday http://t.co/ebz0l2venm': 1,\n",
              " '#FlipkartFashionFriday http://t.co/ebz0l2venm <end>': 1,\n",
              " 'http://t.co/ebz0l2venm <end>': 1,\n",
              " \"<start> we don't\": 1,\n",
              " \"we don't like\": 1,\n",
              " \"don't like to\": 1,\n",
              " 'like to keep': 2,\n",
              " 'to keep our': 1,\n",
              " 'keep our lovely': 1,\n",
              " 'our lovely customers': 1,\n",
              " 'lovely customers waiting': 1,\n",
              " 'customers waiting for': 1,\n",
              " 'waiting for long!': 1,\n",
              " 'for long! we': 1,\n",
              " 'long! we hope': 1,\n",
              " 'we hope you': 5,\n",
              " 'hope you enjoy!': 1,\n",
              " 'you enjoy! happy': 1,\n",
              " 'enjoy! happy friday!': 1,\n",
              " 'happy friday! -': 1,\n",
              " 'friday! - lwwf': 1,\n",
              " '- lwwf :)': 1,\n",
              " 'lwwf :) https://t.co/smyyriipxi': 1,\n",
              " ':) https://t.co/smyyriipxi <end>': 1,\n",
              " 'https://t.co/smyyriipxi <end>': 1,\n",
              " '<start> @impatientraider on': 1,\n",
              " '@impatientraider on second': 1,\n",
              " 'on second thought,': 1,\n",
              " 'second thought, there’s': 1,\n",
              " 'thought, there’s just': 1,\n",
              " 'there’s just not': 1,\n",
              " 'just not enough': 1,\n",
              " 'not enough time': 1,\n",
              " 'enough time for': 1,\n",
              " 'time for a': 5,\n",
              " 'for a dd': 1,\n",
              " 'a dd :)': 1,\n",
              " 'dd :) but': 1,\n",
              " ':) but new': 1,\n",
              " 'but new shorts': 1,\n",
              " 'new shorts entering': 1,\n",
              " 'shorts entering system.': 1,\n",
              " 'entering system. sheep': 1,\n",
              " 'system. sheep must': 1,\n",
              " 'sheep must be': 1,\n",
              " 'must be buying.': 1,\n",
              " 'be buying. <end>': 1,\n",
              " 'buying. <end>': 1,\n",
              " '<start> jgh ,': 1,\n",
              " 'jgh , but': 1,\n",
              " ', but we': 1,\n",
              " 'but we have': 1,\n",
              " 'we have to': 1,\n",
              " 'have to go': 3,\n",
              " 'to go to': 8,\n",
              " 'go to bayan': 1,\n",
              " 'to bayan :d': 1,\n",
              " 'bayan :d bye': 1,\n",
              " ':d bye <end>': 1,\n",
              " 'bye <end>': 1,\n",
              " '<start> as an': 1,\n",
              " 'as an act': 1,\n",
              " 'an act of': 1,\n",
              " 'act of mischievousness,': 1,\n",
              " 'of mischievousness, am': 1,\n",
              " 'mischievousness, am calling': 1,\n",
              " 'am calling the': 1,\n",
              " 'calling the etl': 1,\n",
              " 'the etl layer': 1,\n",
              " 'etl layer of': 1,\n",
              " 'layer of our': 1,\n",
              " 'of our in-house': 1,\n",
              " 'our in-house warehousing': 1,\n",
              " 'in-house warehousing app': 1,\n",
              " 'warehousing app katamari.': 1,\n",
              " 'app katamari. well…': 1,\n",
              " 'katamari. well… as': 1,\n",
              " 'well… as the': 1,\n",
              " 'as the name': 1,\n",
              " 'the name implies': 1,\n",
              " 'name implies :p.': 1,\n",
              " 'implies :p. <end>': 1,\n",
              " ':p. <end>': 1,\n",
              " '<start> #FollowFriday @wncer1': 1,\n",
              " '#FollowFriday @wncer1 @defense_gouv': 1,\n",
              " '@wncer1 @defense_gouv for': 1,\n",
              " '@defense_gouv for being': 1,\n",
              " 'being top influencers': 8,\n",
              " 'top influencers in': 8,\n",
              " 'influencers in my': 8,\n",
              " \"<start> who wouldn't\": 3,\n",
              " \"who wouldn't love\": 3,\n",
              " \"wouldn't love these\": 3,\n",
              " 'love these big....juicy....selfies': 3,\n",
              " 'these big....juicy....selfies :)': 3,\n",
              " 'big....juicy....selfies :) -': 1,\n",
              " ':) - http://t.co/qvzjgd1ufo': 1,\n",
              " '- http://t.co/qvzjgd1ufo http://t.co/owbl11eqry': 1,\n",
              " 'http://t.co/qvzjgd1ufo http://t.co/owbl11eqry <end>': 1,\n",
              " 'http://t.co/owbl11eqry <end>': 1,\n",
              " '<start> @mish23615351 follow': 1,\n",
              " '@mish23615351 follow @jnlazts': 1,\n",
              " 'follow @jnlazts &amp;': 62,\n",
              " '@jnlazts &amp; http://t.co/rcvcyyo0iq': 62,\n",
              " '&amp; http://t.co/rcvcyyo0iq follow': 62,\n",
              " 'http://t.co/rcvcyyo0iq follow u': 62,\n",
              " 'follow u back': 62,\n",
              " 'u back :)': 62,\n",
              " 'back :) <end>': 66,\n",
              " '<start> @jjulieredburn perfect,': 1,\n",
              " '@jjulieredburn perfect, so': 1,\n",
              " 'perfect, so you': 1,\n",
              " 'so you already': 1,\n",
              " 'you already know': 1,\n",
              " \"already know what's\": 1,\n",
              " \"know what's waiting\": 1,\n",
              " \"what's waiting for\": 1,\n",
              " 'waiting for you': 2,\n",
              " 'for you :)': 10,\n",
              " 'you :) <end>': 52,\n",
              " '<start> great new': 1,\n",
              " 'great new opportunity': 1,\n",
              " 'new opportunity for': 1,\n",
              " 'opportunity for junior': 1,\n",
              " 'for junior triathletes': 1,\n",
              " 'junior triathletes aged': 1,\n",
              " 'triathletes aged 12': 1,\n",
              " 'aged 12 and': 1,\n",
              " '12 and 13': 1,\n",
              " 'and 13 at': 1,\n",
              " '13 at the': 1,\n",
              " 'at the gatorade': 1,\n",
              " 'the gatorade series!': 1,\n",
              " 'gatorade series! get': 1,\n",
              " 'series! get your': 1,\n",
              " 'get your entries': 1,\n",
              " 'your entries in': 1,\n",
              " 'entries in :)': 1,\n",
              " 'in :) http://t.co/of3dyozml0': 1,\n",
              " ':) http://t.co/of3dyozml0 <end>': 1,\n",
              " 'http://t.co/of3dyozml0 <end>': 1,\n",
              " '<start> laying out': 1,\n",
              " 'laying out a': 1,\n",
              " 'out a greetings': 1,\n",
              " 'a greetings card': 1,\n",
              " 'greetings card range': 1,\n",
              " 'card range for': 1,\n",
              " 'range for print': 1,\n",
              " 'for print today': 1,\n",
              " 'print today -': 1,\n",
              " 'today - love': 1,\n",
              " '- love my': 1,\n",
              " 'love my job': 1,\n",
              " 'my job :-)': 2,\n",
              " 'job :-) <end>': 3,\n",
              " ':-) <end>': 380,\n",
              " \"<start> friend's lunch...\": 1,\n",
              " \"friend's lunch... yummmm\": 1,\n",
              " 'lunch... yummmm :)': 1,\n",
              " 'yummmm :) #Nostalgia': 1,\n",
              " ':) #Nostalgia #TBS': 1,\n",
              " '#Nostalgia #TBS #KU.': 1,\n",
              " '#TBS #KU. <end>': 1,\n",
              " '#KU. <end>': 1,\n",
              " '<start> @rookiesenpai @arcadester': 1,\n",
              " '@rookiesenpai @arcadester it': 1,\n",
              " '@arcadester it is': 1,\n",
              " 'it is the': 1,\n",
              " 'is the id': 1,\n",
              " 'the id conflict': 1,\n",
              " 'id conflict thanks': 1,\n",
              " 'conflict thanks for': 1,\n",
              " 'thanks for the': 64,\n",
              " 'for the help': 1,\n",
              " 'the help :d': 1,\n",
              " \"help :d here's\": 1,\n",
              " \":d here's the\": 1,\n",
              " \"here's the screenshot\": 1,\n",
              " 'the screenshot of': 1,\n",
              " 'screenshot of it': 1,\n",
              " 'of it working': 1,\n",
              " 'it working <end>': 1,\n",
              " 'working <end>': 1,\n",
              " '<start> @oohdawg_ hi': 1,\n",
              " '@oohdawg_ hi liv': 1,\n",
              " 'hi liv :))': 1,\n",
              " 'liv :)) <end>': 1,\n",
              " ':)) <end>': 72,\n",
              " '<start> hello i': 1,\n",
              " 'hello i need': 1,\n",
              " 'i need to': 7,\n",
              " 'need to know': 2,\n",
              " 'to know something': 1,\n",
              " 'know something can': 1,\n",
              " 'something can u': 1,\n",
              " 'can u fm': 1,\n",
              " 'u fm me': 1,\n",
              " 'fm me on': 1,\n",
              " 'me on twitter??': 1,\n",
              " 'on twitter?? —': 1,\n",
              " 'twitter?? — sure': 1,\n",
              " '— sure thing': 1,\n",
              " 'sure thing :)': 3,\n",
              " 'thing :) dm': 1,\n",
              " ':) dm me': 2,\n",
              " 'dm me x': 1,\n",
              " 'me x http://t.co/w6dy130bv7': 1,\n",
              " 'x http://t.co/w6dy130bv7 <end>': 1,\n",
              " 'http://t.co/w6dy130bv7 <end>': 1,\n",
              " '<start> #FollowFriday @mbandscott_': 1,\n",
              " '#FollowFriday @mbandscott_ @eric_fle': 1,\n",
              " '@mbandscott_ @eric_fle @pointsolutions3': 1,\n",
              " '@eric_fle @pointsolutions3 for': 1,\n",
              " '@pointsolutions3 for being': 1,\n",
              " 'being top new': 5,\n",
              " 'top new followers': 5,\n",
              " 'new followers in': 5,\n",
              " 'followers in my': 5,\n",
              " \"<start> @rossbreadmore i've\": 1,\n",
              " \"@rossbreadmore i've heard\": 1,\n",
              " \"i've heard the\": 1,\n",
              " 'heard the four': 1,\n",
              " 'the four seasons': 1,\n",
              " 'four seasons is': 1,\n",
              " 'seasons is pretty': 1,\n",
              " 'is pretty dope.': 1,\n",
              " 'pretty dope. penthouse,': 1,\n",
              " 'dope. penthouse, obvs': 1,\n",
              " 'penthouse, obvs #Gobigorgohome': 1,\n",
              " 'obvs #Gobigorgohome have': 1,\n",
              " '#Gobigorgohome have fun': 1,\n",
              " \"have fun y'all\": 1,\n",
              " \"fun y'all :)\": 1,\n",
              " \"y'all :) <end>\": 1,\n",
              " '<start> @gculloty87 yeah': 1,\n",
              " '@gculloty87 yeah i': 1,\n",
              " 'yeah i suppose': 1,\n",
              " 'i suppose she': 1,\n",
              " 'suppose she was': 1,\n",
              " 'she was lol!': 1,\n",
              " 'was lol! chat': 1,\n",
              " 'lol! chat in': 1,\n",
              " 'chat in a': 1,\n",
              " 'in a bit': 1,\n",
              " 'a bit just': 1,\n",
              " 'bit just off': 1,\n",
              " 'just off out': 1,\n",
              " 'off out x': 1,\n",
              " 'out x :))': 1,\n",
              " 'x :)) <end>': 1,\n",
              " '<start> hello :)': 21,\n",
              " 'hello :) get': 19,\n",
              " ':) get youth': 19,\n",
              " 'get youth job': 19,\n",
              " 'youth job opportunities': 19,\n",
              " 'job opportunities follow': 19,\n",
              " 'opportunities follow &gt;&gt;': 19,\n",
              " 'follow &gt;&gt; @tolajobjobs': 19,\n",
              " '&gt;&gt; @tolajobjobs @maphisa301': 1,\n",
              " '@tolajobjobs @maphisa301 <end>': 1,\n",
              " '@maphisa301 <end>': 1,\n",
              " '<start> 💅🏽💋 -': 1,\n",
              " '💅🏽💋 - :))))': 1,\n",
              " \"- :)))) haven't\": 1,\n",
              " \":)))) haven't seen\": 1,\n",
              " \"haven't seen you\": 1,\n",
              " 'seen you in': 1,\n",
              " 'you in years': 1,\n",
              " 'in years <end>': 1,\n",
              " 'years <end>': 2,\n",
              " '<start> @bosslogic @amellywood': 1,\n",
              " '@bosslogic @amellywood @cw_arrow': 1,\n",
              " '@amellywood @cw_arrow @arrowwriters': 1,\n",
              " '@cw_arrow @arrowwriters thank': 1,\n",
              " '@arrowwriters thank you!': 1,\n",
              " 'thank you! :-)': 2,\n",
              " 'you! :-) <end>': 3,\n",
              " '<start> @johngutierrez1 hope': 1,\n",
              " '@johngutierrez1 hope the': 1,\n",
              " 'hope the rest': 1,\n",
              " 'the rest of': 6,\n",
              " 'rest of your': 1,\n",
              " 'of your night': 1,\n",
              " 'your night goes': 1,\n",
              " 'night goes by': 1,\n",
              " 'goes by quickly...': 1,\n",
              " 'by quickly... i': 1,\n",
              " 'quickly... i am': 1,\n",
              " 'i am off': 1,\n",
              " 'am off to': 1,\n",
              " 'off to bed...': 1,\n",
              " 'to bed... got': 1,\n",
              " 'bed... got my': 1,\n",
              " 'got my music': 1,\n",
              " 'my music fix': 1,\n",
              " 'music fix and': 1,\n",
              " 'fix and now': 1,\n",
              " 'and now it': 1,\n",
              " 'now it is': 1,\n",
              " 'it is time': 1,\n",
              " 'is time to': 1,\n",
              " 'time to dream': 1,\n",
              " 'to dream :)': 1,\n",
              " 'dream :) <end>': 3,\n",
              " '<start> spiritual ritual': 1,\n",
              " 'spiritual ritual festival': 1,\n",
              " 'ritual festival (népal)': 1,\n",
              " 'festival (népal) beginning': 1,\n",
              " '(népal) beginning of': 1,\n",
              " 'beginning of line-up': 2,\n",
              " 'of line-up :)': 2,\n",
              " 'line-up :) it': 2,\n",
              " ':) it is': 2,\n",
              " 'it is left': 2,\n",
              " 'is left for': 2,\n",
              " 'left for the': 2,\n",
              " 'for the line-up': 2,\n",
              " 'the line-up (y)': 2,\n",
              " 'line-up (y) see': 1,\n",
              " '(y) see more': 1,\n",
              " 'see more at:...': 1,\n",
              " 'more at:... http://t.co/qmnz62oeuc': 1,\n",
              " 'at:... http://t.co/qmnz62oeuc <end>': 1,\n",
              " 'http://t.co/qmnz62oeuc <end>': 1,\n",
              " '<start> @ke7zum hey': 1,\n",
              " '@ke7zum hey sarah!': 1,\n",
              " 'hey sarah! send': 1,\n",
              " 'sarah! send us': 1,\n",
              " 'send us an': 1,\n",
              " 'us an email': 1,\n",
              " 'an email at': 1,\n",
              " 'email at bitsy@bitdefender.com': 1,\n",
              " 'at bitsy@bitdefender.com and': 1,\n",
              " \"bitsy@bitdefender.com and we'll\": 1,\n",
              " \"and we'll help\": 1,\n",
              " \"we'll help you\": 1,\n",
              " 'help you asap': 1,\n",
              " 'you asap :)': 1,\n",
              " 'asap :) <end>': 2,\n",
              " '<start> @izzkamilhalda lols.': 1,\n",
              " '@izzkamilhalda lols. :d': 1,\n",
              " 'lols. :d <end>': 1,\n",
              " ':d <end>': 382,\n",
              " '<start> my kik': 2,\n",
              " 'my kik -': 3,\n",
              " 'kik - hatessuce32429': 1,\n",
              " '- hatessuce32429 #kik': 1,\n",
              " 'hatessuce32429 #kik #kikme': 1,\n",
              " '#kik #kikme #lgbt': 1,\n",
              " '#kikme #lgbt #tinder': 1,\n",
              " '#lgbt #tinder #nsfw': 1,\n",
              " '#tinder #nsfw #akua': 1,\n",
              " '#nsfw #akua #cumshot': 1,\n",
              " '#akua #cumshot :)': 1,\n",
              " '#cumshot :) http://t.co/tnhjd36yzf': 1,\n",
              " ':) http://t.co/tnhjd36yzf <end>': 1,\n",
              " 'http://t.co/tnhjd36yzf <end>': 1,\n",
              " '<start> @kalinwhite come': 1,\n",
              " '@kalinwhite come to': 1,\n",
              " 'come to my': 1,\n",
              " 'to my house': 1,\n",
              " 'my house :)))))': 1,\n",
              " 'house :))))) <end>': 1,\n",
              " ':))))) <end>': 9,\n",
              " '<start> #nsn_supplements, effective': 1,\n",
              " '#nsn_supplements, effective press': 1,\n",
              " 'effective press release': 1,\n",
              " 'press release distribution': 1,\n",
              " 'release distribution with': 1,\n",
              " 'distribution with results!': 1,\n",
              " 'with results! :)': 1,\n",
              " 'results! :) [link': 1,\n",
              " ':) [link removed]': 1,\n",
              " '[link removed] #PressRelease': 1,\n",
              " 'removed] #PressRelease #NewsDistribution': 1,\n",
              " '#PressRelease #NewsDistribution <end>': 1,\n",
              " '#NewsDistribution <end>': 1,\n",
              " '<start> hi bam': 44,\n",
              " 'hi bam !': 44,\n",
              " 'bam ! @barsandmelody': 44,\n",
              " '! @barsandmelody can': 44,\n",
              " '@barsandmelody can you': 44,\n",
              " 'can you follow': 45,\n",
              " 'you follow my': 45,\n",
              " 'follow my bestfriend': 44,\n",
              " 'my bestfriend @969horan696': 44,\n",
              " 'bestfriend @969horan696 ?': 44,\n",
              " '@969horan696 ? she': 44,\n",
              " '? she loves': 44,\n",
              " 'she loves you': 44,\n",
              " 'loves you a': 44,\n",
              " 'you a lot': 44,\n",
              " 'a lot :)': 45,\n",
              " 'lot :) see': 44,\n",
              " ':) see you': 46,\n",
              " 'see you in': 48,\n",
              " 'you in warsaw': 44,\n",
              " 'in warsaw &lt;3': 44,\n",
              " 'warsaw &lt;3 love': 44,\n",
              " '&lt;3 love you': 44,\n",
              " 'love you &lt;3': 45,\n",
              " 'you &lt;3 x46': 1,\n",
              " '&lt;3 x46 <end>': 1,\n",
              " 'x46 <end>': 1,\n",
              " '<start> everyone watch': 1,\n",
              " 'everyone watch the': 1,\n",
              " 'watch the documentary': 1,\n",
              " 'the documentary earthlings': 1,\n",
              " 'documentary earthlings on': 1,\n",
              " 'earthlings on youtube': 1,\n",
              " 'on youtube :-)': 1,\n",
              " 'youtube :-) <end>': 1,\n",
              " '<start> @jamiefigsxx follow': 1,\n",
              " '@jamiefigsxx follow @jnlazts': 1,\n",
              " '<start> #FollowFriday @michelbauza': 1,\n",
              " '#FollowFriday @michelbauza @invataonline': 1,\n",
              " '@michelbauza @invataonline for': 1,\n",
              " '@invataonline for being': 1,\n",
              " 'being top supports': 5,\n",
              " 'top supports in': 5,\n",
              " 'supports in my': 5,\n",
              " '<start> buuuuuuuut oh': 1,\n",
              " 'buuuuuuuut oh well': 1,\n",
              " 'oh well :-)': 1,\n",
              " 'well :-) <end>': 3,\n",
              " '<start> @leisuremarkltd @noshandquaff': 1,\n",
              " '@leisuremarkltd @noshandquaff @aktarislam': 1,\n",
              " '@noshandquaff @aktarislam @keanebrands': 1,\n",
              " '@aktarislam @keanebrands @heritagesilver': 1,\n",
              " '@keanebrands @heritagesilver i': 1,\n",
              " '@heritagesilver i am': 1,\n",
              " 'i am looking': 1,\n",
              " 'am looking forward': 1,\n",
              " 'looking forward to': 17,\n",
              " 'forward to visiting': 1,\n",
              " 'to visiting next': 1,\n",
              " 'visiting next week': 1,\n",
              " 'next week #letsgetmessy': 1,\n",
              " 'week #letsgetmessy jo': 1,\n",
              " '#letsgetmessy jo :-)': 1,\n",
              " 'jo :-) <end>': 1,\n",
              " '<start> @sehunshinedaily if': 1,\n",
              " '@sehunshinedaily if it': 1,\n",
              " 'if it makes': 1,\n",
              " 'it makes u': 1,\n",
              " 'makes u feel': 1,\n",
              " 'u feel better': 2,\n",
              " 'feel better i': 1,\n",
              " 'better i never': 1,\n",
              " 'i never have': 1,\n",
              " 'never have nor': 1,\n",
              " 'have nor will': 1,\n",
              " 'nor will see': 1,\n",
              " 'will see anyone': 1,\n",
              " 'see anyone in': 1,\n",
              " 'anyone in kpop': 1,\n",
              " 'in kpop in': 1,\n",
              " 'kpop in the': 1,\n",
              " 'in the flesh': 1,\n",
              " 'the flesh :d': 1,\n",
              " 'flesh :d <end>': 1,\n",
              " '<start> @joyster2012 @cathstaincliffe': 1,\n",
              " '@joyster2012 @cathstaincliffe good': 1,\n",
              " '@cathstaincliffe good for': 1,\n",
              " 'good for you,': 1,\n",
              " 'for you, girl!!': 1,\n",
              " 'you, girl!! best': 1,\n",
              " 'girl!! best wishes': 1,\n",
              " 'best wishes :-)': 1,\n",
              " 'wishes :-) <end>': 1,\n",
              " '<start> @_kimimi a': 1,\n",
              " '@_kimimi a great': 1,\n",
              " 'a great enough': 1,\n",
              " 'great enough reason': 1,\n",
              " 'enough reason to': 1,\n",
              " 'reason to listen': 1,\n",
              " 'to listen to': 2,\n",
              " 'listen to one': 1,\n",
              " 'to one epic': 1,\n",
              " 'one epic soundtrack.': 1,\n",
              " 'epic soundtrack. :d': 1,\n",
              " 'soundtrack. :d <end>': 1,\n",
              " '<start> @aquadesigngroup thank': 1,\n",
              " '@aquadesigngroup thank you': 1,\n",
              " 'thank you for': 45,\n",
              " 'you for the': 10,\n",
              " 'for the shout': 4,\n",
              " 'the shout out.': 1,\n",
              " 'shout out. have': 1,\n",
              " 'out. have a': 1,\n",
              " 'have a great': 44,\n",
              " 'a great friday': 6,\n",
              " 'great friday :)': 3,\n",
              " 'friday :) <end>': 8,\n",
              " '<start> i added': 3,\n",
              " 'i added a': 3,\n",
              " 'added a video': 3,\n",
              " 'a video to': 3,\n",
              " 'video to a': 3,\n",
              " 'to a @youtube': 3,\n",
              " 'a @youtube playlist': 3,\n",
              " '@youtube playlist http://t.co/yzpfsmxuq0': 1,\n",
              " 'playlist http://t.co/yzpfsmxuq0 im': 1,\n",
              " 'http://t.co/yzpfsmxuq0 im back': 1,\n",
              " 'im back on': 3,\n",
              " 'back on twitch': 3,\n",
              " 'on twitch and': 3,\n",
              " 'twitch and today': 3,\n",
              " 'and today it': 3,\n",
              " 'today it going': 3,\n",
              " 'it going to': 3,\n",
              " 'going to be': 15,\n",
              " 'to be league': 3,\n",
              " 'be league :)': 3,\n",
              " 'league :) -': 3,\n",
              " ':) - 1': 3,\n",
              " '- 1 /': 3,\n",
              " '1 / 4': 1,\n",
              " '/ 4 <end>': 1,\n",
              " '4 <end>': 2,\n",
              " '<start> would love': 1,\n",
              " 'would love to': 6,\n",
              " 'love to see': 1,\n",
              " 'to see you': 12,\n",
              " 'see you dear': 1,\n",
              " 'you dear in': 1,\n",
              " 'dear in #Jordan': 1,\n",
              " 'in #Jordan :)': 1,\n",
              " '#Jordan :) waiting': 1,\n",
              " ':) waiting you!': 1,\n",
              " 'waiting you! @firdoz': 1,\n",
              " 'you! @firdoz :)': 1,\n",
              " '@firdoz :) @visitjordan': 1,\n",
              " ':) @visitjordan @dannyprol': 1,\n",
              " '@visitjordan @dannyprol <end>': 1,\n",
              " '@dannyprol <end>': 1,\n",
              " '<start> @abnormal_ana92 oh,': 1,\n",
              " '@abnormal_ana92 oh, okay': 1,\n",
              " 'oh, okay :d': 1,\n",
              " 'okay :d thanks!': 1,\n",
              " ':d thanks! <end>': 1,\n",
              " '<start> @sssniperwolf like': 1,\n",
              " '@sssniperwolf like how': 1,\n",
              " 'like how to': 1,\n",
              " 'how to fake': 1,\n",
              " 'to fake gameplays': 1,\n",
              " 'fake gameplays ;)': 1,\n",
              " 'gameplays ;) haha': 1,\n",
              " ';) haha im': 1,\n",
              " 'haha im kidding,': 1,\n",
              " 'im kidding, im': 1,\n",
              " 'kidding, im kidding.': 1,\n",
              " 'im kidding. you': 1,\n",
              " 'kidding. you do': 1,\n",
              " 'you do good': 1,\n",
              " 'do good stuff': 1,\n",
              " 'good stuff :).': 2,\n",
              " 'stuff :). <end>': 1,\n",
              " ':). <end>': 6,\n",
              " '<start> @dennislami @dicle_aygur,': 1,\n",
              " '@dennislami @dicle_aygur, yeah': 1,\n",
              " '@dicle_aygur, yeah exactly': 1,\n",
              " 'yeah exactly :)': 1,\n",
              " 'exactly :) <end>': 1,\n",
              " '<start> our new': 1,\n",
              " 'our new product': 1,\n",
              " 'new product line': 1,\n",
              " 'product line is': 1,\n",
              " 'line is in': 1,\n",
              " 'is in our': 1,\n",
              " 'in our #etsy': 1,\n",
              " 'our #etsy shop': 1,\n",
              " '#etsy shop now!': 1,\n",
              " 'shop now! check': 1,\n",
              " 'now! check it': 1,\n",
              " 'check it out': 4,\n",
              " 'it out :)': 2,\n",
              " 'out :) http://t.co/h8exctlqxg': 1,\n",
              " ':) http://t.co/h8exctlqxg #boxroomcrafts': 1,\n",
              " 'http://t.co/h8exctlqxg #boxroomcrafts <end>': 1,\n",
              " '#boxroomcrafts <end>': 1,\n",
              " '<start> @peakyourmind i': 1,\n",
              " '@peakyourmind i hope': 1,\n",
              " 'i hope your': 2,\n",
              " 'hope your vacation': 1,\n",
              " 'your vacation is': 1,\n",
              " 'vacation is going': 1,\n",
              " 'is going great!': 1,\n",
              " 'going great! :d': 1,\n",
              " 'great! :d <end>': 1,\n",
              " '<start> @groovinshawn they': 1,\n",
              " '@groovinshawn they are': 1,\n",
              " 'they are rechargeable': 1,\n",
              " 'are rechargeable and': 1,\n",
              " 'rechargeable and it': 1,\n",
              " 'and it normally': 1,\n",
              " 'it normally comes': 1,\n",
              " 'normally comes with': 1,\n",
              " 'comes with a': 1,\n",
              " 'with a charger': 1,\n",
              " 'a charger when': 1,\n",
              " 'charger when u': 1,\n",
              " 'when u buy': 1,\n",
              " 'u buy it': 1,\n",
              " 'buy it :)': 2,\n",
              " 'it :) <end>': 24,\n",
              " '<start> #FollowFriday @france_espana': 1,\n",
              " '#FollowFriday @france_espana @reglisse_menthe': 1,\n",
              " '@france_espana @reglisse_menthe @cci_inter': 1,\n",
              " '@reglisse_menthe @cci_inter for': 1,\n",
              " '@cci_inter for being': 1,\n",
              " \"<start> well she's\": 1,\n",
              " \"well she's asleep\": 1,\n",
              " \"she's asleep and\": 1,\n",
              " 'asleep and i': 2,\n",
              " 'and i have': 7,\n",
              " 'i have no': 5,\n",
              " 'have no one': 1,\n",
              " 'no one to': 1,\n",
              " 'one to talk': 1,\n",
              " 'to talk to': 2,\n",
              " 'talk to sooo': 1,\n",
              " 'to sooo someone': 1,\n",
              " 'sooo someone text': 1,\n",
              " 'someone text me': 1,\n",
              " 'text me :)': 1,\n",
              " 'me :) <end>': 26,\n",
              " '<start> @brynybrath @smallcappy': 1,\n",
              " '@brynybrath @smallcappy yes,': 1,\n",
              " '@smallcappy yes, i': 1,\n",
              " 'yes, i suppose.': 1,\n",
              " 'i suppose. i': 1,\n",
              " 'suppose. i bet': 1,\n",
              " \"i bet he'll\": 1,\n",
              " \"bet he'll have\": 1,\n",
              " \"he'll have a\": 1,\n",
              " 'have a blue': 1,\n",
              " 'a blue fit': 1,\n",
              " 'blue fit after': 1,\n",
              " 'fit after hearing': 1,\n",
              " 'after hearing her': 1,\n",
              " 'hearing her speech': 1,\n",
              " 'her speech today.': 1,\n",
              " 'speech today. pity': 1,\n",
              " 'today. pity :-)': 1,\n",
              " 'pity :-) <end>': 1,\n",
              " '<start> green gardens,': 1,\n",
              " 'green gardens, midnight': 1,\n",
              " 'gardens, midnight sun,': 1,\n",
              " 'midnight sun, beautiful': 1,\n",
              " 'sun, beautiful canals': 1,\n",
              " 'beautiful canals dasvidaniya': 1,\n",
              " 'canals dasvidaniya till': 1,\n",
              " 'dasvidaniya till next': 1,\n",
              " 'till next visit.:)': 1,\n",
              " 'next visit.:) <end>': 1,\n",
              " 'visit.:) <end>': 1,\n",
              " '<start> @keithrparsons are': 1,\n",
              " '@keithrparsons are you': 1,\n",
              " 'are you scouting': 1,\n",
              " 'you scouting sg': 1,\n",
              " 'scouting sg for': 1,\n",
              " 'sg for a': 1,\n",
              " 'for a future': 1,\n",
              " 'a future wlan': 1,\n",
              " 'future wlan pros': 1,\n",
              " 'wlan pros conference': 1,\n",
              " 'pros conference here': 1,\n",
              " 'conference here in': 1,\n",
              " 'here in asia?': 1,\n",
              " 'in asia? :)': 1,\n",
              " 'asia? :) <end>': 1,\n",
              " '<start> @cecilie_hell @420evilangel': 1,\n",
              " '@cecilie_hell @420evilangel @wazimotometal': 1,\n",
              " '@420evilangel @wazimotometal @durooooooo': 1,\n",
              " '@wazimotometal @durooooooo @spigranty': 1,\n",
              " '@durooooooo @spigranty good': 1,\n",
              " '@spigranty good for': 1,\n",
              " 'good for u,': 1,\n",
              " 'for u, better': 1,\n",
              " 'u, better change': 1,\n",
              " 'better change it': 1,\n",
              " 'change it to': 1,\n",
              " 'it to lollipop': 1,\n",
              " 'to lollipop 🍭': 1,\n",
              " 'lollipop 🍭 :).': 1,\n",
              " '🍭 :). <end>': 1,\n",
              " '<start> we &lt;3': 1,\n",
              " 'we &lt;3 u': 1,\n",
              " '&lt;3 u nez': 1,\n",
              " 'u nez :)': 1,\n",
              " 'nez :) #AGNEZMO': 1,\n",
              " ':) #AGNEZMO https://t.co/cgvimhsinz': 1,\n",
              " '#AGNEZMO https://t.co/cgvimhsinz <end>': 1,\n",
              " 'https://t.co/cgvimhsinz <end>': 1,\n",
              " '<start> @littlemix follow': 1,\n",
              " '@littlemix follow me': 1,\n",
              " 'follow me please': 2,\n",
              " 'me please :)': 1,\n",
              " 'please :) this': 1,\n",
              " ':) this is': 2,\n",
              " 'this is my': 1,\n",
              " 'is my big': 1,\n",
              " 'my big dream': 1,\n",
              " 'big dream :)': 1,\n",
              " '<start> @elemaaan oley': 1,\n",
              " '@elemaaan oley be': 1,\n",
              " 'oley be :d': 1,\n",
              " 'be :d <end>': 2,\n",
              " '<start> \"@cowokaddict: mama': 1,\n",
              " '\"@cowokaddict: mama is': 1,\n",
              " 'mama is the': 1,\n",
              " 'is the only': 2,\n",
              " 'the only reason': 2,\n",
              " 'only reason why': 1,\n",
              " 'reason why i': 1,\n",
              " 'why i stand': 1,\n",
              " 'i stand stronger': 1,\n",
              " 'stand stronger up': 1,\n",
              " 'stronger up to': 1,\n",
              " 'up to now!': 1,\n",
              " 'to now! :)\"': 1,\n",
              " 'now! :)\" <end>': 1,\n",
              " ':)\" <end>': 12,\n",
              " '<start> @macatangayapril follow': 1,\n",
              " '@macatangayapril follow @jnlazts': 1,\n",
              " '<start> @tk_kjk_kndr @boukendreamer': 1,\n",
              " '@tk_kjk_kndr @boukendreamer oh': 1,\n",
              " '@boukendreamer oh my': 1,\n",
              " 'oh my god': 2,\n",
              " 'my god misty,': 1,\n",
              " 'god misty, my': 1,\n",
              " 'misty, my baby': 1,\n",
              " 'my baby is': 1,\n",
              " 'baby is so': 1,\n",
              " 'is so cute!!!': 1,\n",
              " 'so cute!!! :d': 1,\n",
              " 'cute!!! :d <end>': 1,\n",
              " '<start> @bhaktisbanter i': 1,\n",
              " '@bhaktisbanter i love': 1,\n",
              " 'i love blue': 1,\n",
              " 'love blue :)': 1,\n",
              " 'blue :) #FlipkartFashionFriday': 1,\n",
              " ':) #FlipkartFashionFriday http://t.co/hnbinh35es': 1,\n",
              " '#FlipkartFashionFriday http://t.co/hnbinh35es <end>': 1,\n",
              " 'http://t.co/hnbinh35es <end>': 1,\n",
              " '<start> @carcassdrop woohoo!': 1,\n",
              " \"@carcassdrop woohoo! can't\": 1,\n",
              " \"woohoo! can't wait\": 1,\n",
              " \"can't wait :)\": 2,\n",
              " 'wait :) have': 1,\n",
              " ':) have you': 3,\n",
              " 'have you signed': 2,\n",
              " 'you signed up': 2,\n",
              " 'signed up yet,': 1,\n",
              " 'up yet, or': 1,\n",
              " 'yet, or still': 1,\n",
              " 'or still thinking': 1,\n",
              " 'still thinking about': 1,\n",
              " 'thinking about it?': 1,\n",
              " 'about it? mka': 1,\n",
              " 'it? mka <end>': 1,\n",
              " 'mka <end>': 5,\n",
              " '<start> i have': 12,\n",
              " 'i have liam': 1,\n",
              " 'have liam access': 1,\n",
              " 'liam access now': 1,\n",
              " 'access now :))': 1,\n",
              " 'now :)) <end>': 1,\n",
              " '<start> @syuhxdxtengku most': 1,\n",
              " '@syuhxdxtengku most welcome': 1,\n",
              " 'most welcome :)': 2,\n",
              " 'welcome :) <end>': 11,\n",
              " '<start> stats for': 60,\n",
              " 'stats for the': 60,\n",
              " 'for the day': 45,\n",
              " 'the day have': 44,\n",
              " 'day have arrived.': 44,\n",
              " 'have arrived. 1': 44,\n",
              " 'arrived. 1 new': 44,\n",
              " '1 new follower': 44,\n",
              " 'new follower and': 44,\n",
              " 'follower and no': 44,\n",
              " 'and no unfollowers': 60,\n",
              " 'no unfollowers :)': 60,\n",
              " 'unfollowers :) via': 60,\n",
              " ':) via http://t.co/p6k6sih58a.': 1,\n",
              " 'via http://t.co/p6k6sih58a. <end>': 1,\n",
              " 'http://t.co/p6k6sih58a. <end>': 1,\n",
              " '<start> @sluttywife2 you': 1,\n",
              " \"@sluttywife2 you shouldn't\": 1,\n",
              " \"you shouldn't be\": 1,\n",
              " \"shouldn't be surprised...you\": 1,\n",
              " 'be surprised...you have': 1,\n",
              " 'surprised...you have an': 1,\n",
              " 'have an amazing': 5,\n",
              " 'an amazing figure': 1,\n",
              " 'amazing figure :)': 1,\n",
              " 'figure :) <end>': 1,\n",
              " '<start> #FollowFriday @murtishaw': 1,\n",
              " '#FollowFriday @murtishaw @aqui_fr': 1,\n",
              " '@murtishaw @aqui_fr @frtechstartups': 1,\n",
              " '@aqui_fr @frtechstartups for': 1,\n",
              " '@frtechstartups for being': 1,\n",
              " '<start> #HappyBirthdayEmilyBett @emilybett': 1,\n",
              " '#HappyBirthdayEmilyBett @emilybett :)': 1,\n",
              " '@emilybett :) wishing': 1,\n",
              " ':) wishing you': 1,\n",
              " 'wishing you all': 1,\n",
              " 'you all the': 4,\n",
              " 'all the best': 6,\n",
              " 'the best you': 1,\n",
              " 'best you beautiful,sweet,talented,amazing…': 1,\n",
              " 'you beautiful,sweet,talented,amazing… https://t.co/humtc1tr3i': 1,\n",
              " 'beautiful,sweet,talented,amazing… https://t.co/humtc1tr3i <end>': 1,\n",
              " 'https://t.co/humtc1tr3i <end>': 1,\n",
              " '<start> 2 plans': 1,\n",
              " '2 plans for': 1,\n",
              " 'plans for the': 2,\n",
              " 'the day down': 1,\n",
              " 'day down the': 1,\n",
              " 'down the drain': 1,\n",
              " 'the drain great': 1,\n",
              " 'drain great :):': 1,\n",
              " 'great :): <end>': 1,\n",
              " ':): <end>': 2,\n",
              " '<start> @x123456789tine @5sos_fahupdates': 1,\n",
              " '@x123456789tine @5sos_fahupdates gotta': 1,\n",
              " '@5sos_fahupdates gotta love': 1,\n",
              " 'gotta love timezones': 1,\n",
              " 'love timezones :p': 1,\n",
              " 'timezones :p <end>': 1,\n",
              " ':p <end>': 97,\n",
              " '<start> are your': 1,\n",
              " 'are your parents': 1,\n",
              " 'your parents proud': 1,\n",
              " 'parents proud of': 1,\n",
              " 'proud of you': 3,\n",
              " 'of you —': 1,\n",
              " 'you — lol,': 1,\n",
              " '— lol, not': 1,\n",
              " 'lol, not in': 1,\n",
              " 'not in the': 2,\n",
              " 'in the least': 1,\n",
              " 'the least :d': 1,\n",
              " 'least :d maybe': 1,\n",
              " ':d maybe sometimes': 1,\n",
              " 'maybe sometimes they': 1,\n",
              " 'sometimes they get': 1,\n",
              " 'they get happy': 1,\n",
              " 'get happy because': 1,\n",
              " 'happy because of': 1,\n",
              " 'because of my': 2,\n",
              " 'of my grades,': 1,\n",
              " 'my grades, al...': 1,\n",
              " 'grades, al... http://t.co/bjjegioogu': 1,\n",
              " 'al... http://t.co/bjjegioogu <end>': 1,\n",
              " 'http://t.co/bjjegioogu <end>': 1,\n",
              " '<start> grande :)': 1,\n",
              " 'grande :) https://t.co/gsaaxnpr8u': 1,\n",
              " ':) https://t.co/gsaaxnpr8u <end>': 1,\n",
              " 'https://t.co/gsaaxnpr8u <end>': 1,\n",
              " '<start> manila_bro has': 1,\n",
              " 'manila_bro has chosen': 1,\n",
              " 'has chosen to': 1,\n",
              " 'chosen to follow': 1,\n",
              " 'to follow me': 1,\n",
              " 'follow me on': 3,\n",
              " 'me on twitter!': 2,\n",
              " 'on twitter! http://t.co/lkxzwxn1fb.': 1,\n",
              " 'twitter! http://t.co/lkxzwxn1fb. thanks': 1,\n",
              " 'http://t.co/lkxzwxn1fb. thanks for': 1,\n",
              " 'for the follow': 20,\n",
              " 'the follow :)': 6,\n",
              " 'follow :) <end>': 4,\n",
              " '<start> @syazwanzainal sure': 1,\n",
              " '@syazwanzainal sure let': 1,\n",
              " 'sure let me': 1,\n",
              " 'let me know': 29,\n",
              " 'me know when': 1,\n",
              " \"know when you're\": 1,\n",
              " \"when you're around..at\": 1,\n",
              " \"you're around..at this\": 1,\n",
              " 'around..at this side': 1,\n",
              " 'this side of': 1,\n",
              " 'side of the': 1,\n",
              " 'of the world': 2,\n",
              " 'the world #eh': 1,\n",
              " 'world #eh u': 1,\n",
              " '#eh u too': 1,\n",
              " 'u too take': 1,\n",
              " 'too take care': 1,\n",
              " 'take care :-)': 1,\n",
              " 'care :-) <end>': 1,\n",
              " '<start> #FollowFriday @michae1green': 1,\n",
              " '#FollowFriday @michae1green @superninjaalan': 1,\n",
              " '@michae1green @superninjaalan @doug_laney': 1,\n",
              " '@superninjaalan @doug_laney for': 1,\n",
              " '@doug_laney for being': 1,\n",
              " '<start> finally the': 1,\n",
              " 'finally the fucking': 1,\n",
              " 'the fucking weekend': 1,\n",
              " 'fucking weekend :)': 1,\n",
              " 'weekend :) <end>': 17,\n",
              " '<start> real :)': 1,\n",
              " ...}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "create_n_gram(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-smoothing 2.000033738191633\n",
            "('please :)', 10.000033738191632)\n",
            "('please follow', 8.000033738191632)\n",
            "('please do', 6.000033738191633)\n",
            "('please dm', 4.000033738191633)\n",
            "('please employers!', 3.000033738191633)\n"
          ]
        }
      ],
      "source": [
        "def find_the_next_word(sentence):\n",
        "\n",
        "    k = 0.01\n",
        "    \n",
        "    # Creating n gram based on the all arguments length\n",
        "    all_vocab = create_n_gram(len(sentence.split()))\n",
        "\n",
        "    # Placing all the arguments in a list\n",
        "    all_words = sentence.split()\n",
        "\n",
        "    # Getting all the words except last word\n",
        "    early_words = \" \".join(all_words[:-1])\n",
        "\n",
        "    \n",
        "\n",
        "    last_word = all_words[-1]\n",
        "    \n",
        "    # \n",
        "    all_text1 = [key for key in all_vocab.keys() if early_words in key]\n",
        "    all_text2 = [key for key in all_vocab.keys() if last_word in key]\n",
        "\n",
        "\n",
        "    k_smoothing_for_given_word = all_vocab[f\"{early_words} {last_word}\"] + k / (len(all_text1) + (k*uni_gram_length))\n",
        "    print(f\"K-smoothing {k_smoothing_for_given_word}\")\n",
        "    \n",
        "    all_prob = {}\n",
        "    for each_text in all_text1:\n",
        "        if each_text.split()[0] == early_words:\n",
        "            second_word = each_text.split()[1]\n",
        "            prob_of_given_words = all_vocab[f\"{early_words} {second_word}\"] + k / (len(all_text1) + (k*uni_gram_length))\n",
        "            all_prob[f\"{early_words} {second_word}\"] = prob_of_given_words\n",
        "    top_recommend = (sorted(all_prob.items(),key=lambda x: x[1],reverse=True))[:5]\n",
        "    for each_recommendation in top_recommend:\n",
        "        print(each_recommendation)\n",
        "find_the_next_word('please call')\n",
        "# find_the_next_word('this','week',':)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
